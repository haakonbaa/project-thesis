\chapter{Task-Priority Control}

This chapter explores various methods for task priority control, beginning with
an introduction to its fundamental concepts and a presentation of one of the
earliest and most straightforward techniques. It then continues into more advanced
approaches and concludes with a discussion of key implementation considerations,
including singularity robustness, for real-world robotic applications.

% -----------------------------------------------------------------------------
\section{Introduction}
\label{sec:tpc_intro}
\iffalse
Task priority control addresses the problem of managing multiple objectives simultaneously.
Each task is assigned a specific priority level, and the goal is to prioritize the higher-level
tasks my minimizing its error while balancing the lower-priority objectives. The
following sections are based largely on the work of \cite{antonelli2009}, which provides
an excellent overview of the topic in terms of velocity level control. The concepts
of velocity-, acceleration- and force-level control are to be defined in the
following sections.
\fi

Task priority control addresses the problem of managing multiple objectives simultaneously in a robotic system. It is a widely used methodology for handling redundancy in robots, enabling them to perform several tasks at once without compromising the executing of higher-priority objectives. Understanding the concept of tasks, their prioritization, and how multiple tasks interact is essential for ounderstanding the fundamentals of task priority control.

A task referes to a specific objective or goal that a robotic system aims to acheive. Tasks can represent a wide variety of objectives, such as moving an end-effector to a desired position and orientation, maintaining a specific posture, avoiding joint limits, preventing collisions, or controlling specific velocities or accelerations at specific points. The tasks are typically described using functions, which map system states to task-specific outputs. These outputs are then often compared to desired values to determine the error and guide the control system towards acheiving the task.

The prioritization of tasks is a key aspect of task-priority control. When a task is assigned a higher priority, it must be executed without being disturbed or compromised by lower-priority tasks. This means that the control system must balance the objectives of multiple tasks, ensuring that the higher-priority tasks are acheived while still allowing the lower-priority tasks to be executed. In practice, higher priority tasks are resolved first, and the remaining degrees of freedom are used to acheive the lower-priority tasks. For example, a robotic manipulator tasked with avoiding obstacles might prioritize obstacle avoidance over maintaining an exact end-effector position.

In the following sections, we will develop the mathematical foundations of task-priority control, exploring the concepts of velocity-, acceleration-, and force/torque-level control.

% -----------------------------------------------------------------------------
\section{Kinematic-level Redundancy Resolution}

Kinematic-level redundancy resolution is a fundamental concept in task-priority control.
It is one of the first methods proposed for handling redundancy in a task-priority framework.
A fundamental assumption in kinematic-level redundancy resolution is that there
allready exists a controller that can generate the desired joint velocities $\dot{\bm{q}}_d(t)$.
Considerations around this assumption will be discussed in later sections.
The mathematical concepts introduced in this section are presented in introductory
chapters in many of the articles and books on task-priority control, such as
\cite{hanafusa1981}, \cite{nakamura1987}, \cite{khatib1987}. An overview is
presented in \cite{chiaverini1997}.

\subsection{Velocity-level control}

A task variable $\bm{\sigma}(t) \in \mathbb{R}^m$ is defined as a function of the robot's
joint variables $\bm{q}(t) \in \mathbb{R}^n$.
\begin{align}
    \bm{\sigma}(t) = \bm{f}(\bm{q}(t)) \label{eq:def_task}
\end{align}
A task can then be defined as the objective of keeping the task variable $\bm{\sigma}(t)$
close to a desired value $\bm{\sigma}_d(t) \in \mathbb{R}^m$. For instance, a task could
be the end-effector position of a robot manipulator or the orientation of a camera mounted
on a robot. By differentiating \autoref{eq:def_task} with respect to time, the task velocity
can be defined as
\begin{align}
    \dot{\bm{\sigma}}(t) = \frac{\partial \bm{f}(\bm{q}(t))}{\partial \bm{q}} \dot{\bm{q}}(t)= \bm{J}(\bm{q}(t)) \dot{\bm{q}}(t) \label{eq:def_task_jacobian}
\end{align}

The matrix $\bm{J}(\bm{q}(t)) \in \mathbb{R}^{n \times m}$ is called the
\emph{task Jacobian}, or simply the \emph{Jacobian}, and maps the joint
velocities $\dot{\bm{q}}(t)$ to the task velocity $\dot{\bm{\sigma}}(t)$.
The Jacobian is a function of the robot's joint variables $\bm{q}(t)$.
In the case where only one task is considered, one can use the pseudoinverse
to compute the minimum norm joint velocities that will achieve the desired
task velocity. The joint velocities are then given by
\begin{align}
    \dot{\bm{q}}_d(t) = \bm{J}^{+}(\bm{q}(t)) \dot{\bm{\sigma}}_d(t) \label{eq:task_priority}
\end{align}
where $\bm{J}^{+}(\bm{q}(t))$ is the pseudoinverse of the Jacobian at the current
joint configuration $\bm{q}(t)$. From now on the dependencies of $\bm{J}$, $\bm{q}$
and $\bm{\sigma}$ will be omitted for brevity.

In practice the jacobian might not represent the true kinematics of the robot.
Furthermore, depending on the task, the desired task velocity might not be feasible,
and there might be model errors and noise in the estimated joint velocities making
the joint velocities not equal to the desired joint velocities. Because of this,
a feedback controller is needed to ensure that the desired task velocity is
achieved. Substituting the desired task velocity $\dot{\bm{\sigma}}_d(t)$ in 
\autoref{eq:task_priority} with
a feedforward term and a feedback term, the joint velocities can be computed as
\begin{align}
    \dot{\bm{q}}_d = \bm{J}^{+} \left(\dot{\bm{\sigma}}_d + \bm{\Lambda}\tilde{\bm{\sigma}}\right)
\end{align}
Where $\tilde{\bm{\sigma}} = \bm{\sigma} - \bm{\sigma}_d$ is the error in the
task and the constant matrix $\bm{\Lambda}$ is a matrix that determines the
feedback gains.
Generalizing this to multiple tasks, we note that \autoref{eq:def_task_jacobian}
has a more general solution than \autoref{eq:task_priority} when $n > m$:
\begin{align}
    \dot{\bm{q}}_d = \bm{J}^{+} \dot{\bm{\sigma}}_d + (\mathbb{I} - \bm{J}^{+} \bm{J}) \bm{z}
\end{align}
for some arbitrary vector $\bm{z} \in \mathbb{R}^n$. The term
$(\mathbb{I}_n - \bm{J}^{+} \bm{J}) \bm{z}$ is recognized as the null space projection
of $\bm{z}$ onto the null space of the Jacobian matrix $\bm{J}$. By setting
$\bm{z}$ to some desired value, such as the joint velocities of a lower-priority task,
one can achieve prioritization of tasks. To present the basic idea, consider the
tasks
\begin{subequations}
\begin{align}
    \bm{\sigma}_i &= \bm{f}_i(\bm{q}) \in \mathbb{R}^{m_i} &i &= 1, 2, \ldots, k \\
    \dot{\bm{\sigma}}_i &= \bm{J}_i(\bm{q}) \dot{\bm{q}} \in \mathbb{R}^{m_i} &i &= 1, 2, \ldots, k
\end{align}
\end{subequations}
with corresponding desired tasks
\begin{align}
    \dot{\bm{\sigma}}_{i,d}(t) \quad i = 1, 2, \ldots, k
\end{align}
Let $\bm{N}_i = \mathbb{I}_n - \bm{J}_i^{+} \bm{J}_i$ be the null space projection
matrix onto the null space of the Jacobian $\bm{J}_i$.
The desired joint velocities are then given by
\begin{align}
    \dot{\bm{q}}_d = \sum_{i=1}^k \bm{N}_i^{\#}\bm{J}_i^{\#} \left(\dot{\bm{\sigma}}_{i,d} + \bm{\Lambda}_i \tilde{\bm{\sigma}}_i\right) \label{eq:task_priority_vel}
\end{align}
comparing this to the single task case, $\bm{N}_i^{\#}$ is the null space projection matrix
projecting a task onto the null space of all the higher-priority tasks.
\begin{align}
    \bm{N}_i^{\#} = \bm{N}_1 \bm{N}_2 \cdots \bm{N}_{i-1}
\end{align}
and the $\bm{J}_i^{\#}$ matrix is the projection matrix projecting a task onto the
subspace spanned by the task Jacobian.
\begin{align}
    \bm{J}_i^{\#} = \bm{J}_i^+
\end{align}
In general, several slightly different task priority control frameworks have
been proposed, following the same basic form as \autoref{eq:task_priority_vel}.
Although, slight variations in the form of the null space projection matrices
and the pseudoinverse matrices have been proposed. The methods include substituting
the pseudoinverse with the transpose of the Jacobian, and using augmented null space
projections.
\begin{subequations}
    \label{eq:augmented_null_space}
\begin{align}
    \bm{N}_i^{\#} := \bm{N}_{1\cdots i-1} := \mathbb{I} - \bm{J}_{1\cdots i-1}^+ \bm{J}_{1\cdots i-1} \\
    \bm{J}_{1\cdots i-1} := \begin{bmatrix}
        J_1 \\
        J_2 \\
        \vdots \\
        J_{i-1}
    \end{bmatrix}
\end{align}
\end{subequations}
This gives rise to several different variants of the task priority control algorithm.
The variants discussed in \cite{antonelli2009} are summarized in the following table:
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        $J^{\#}$ & $N^{\#}$ & Algorithm's name \\
        \hline
        $\bm{J}^+$ & $\bm{N}_1 \bm{N}_2 \cdots \bm{N}_{i-1}$ & successive inverse-based projections \\
        $\bm{J}^+$ & $\bm{N}_{1\cdots i-1}$ & augmented inverse-based projections \\
        $\bm{J}^T$ & $\bm{N}_1 \bm{N}_2 \cdots \bm{N}_{i-1}$ & successive transpose-based projections \\
        $\bm{J}^T$ & $\bm{N}_{1\cdots i-1}$ & augmented transpose-based projections \\
        \hline
    \end{tabular}
    \label{tab:tpc_variants}
    \caption{Task priority control variants. Table from \cite{antonelli2009}}
\end{table}

Using the successive method, task velocities are progressively projected into the null space of higher-priority tasks by recursively multiplying null space projection matrices. In contrast, the augmented method constructs a single null space projection matrix by stacking the task Jacobians of all higher-priority tasks and then computing the pseudoinverse of this stacked matrix. This distinction is illustrated in \autoref{eq:augmented_null_space}.
It is important to emphasize that these two approaches are not equivalent. Null space projection matrices are generally not commutative, which means the successive method can yield a more conservative null space projection, whereas the augmented method often results in a less conservative projection, offering increased flexibility for lower-priority tasks.
From a computational perspective, the successive method is typically more efficient because it recursively computes the null space projection matrices. Conversely, the augmented method demands the computation of the pseudoinverse of a potentially large stacked Jacobian matrix, which is computationally more intensive.

% -----------------------------------------------------------------------------
\subsection{Acceleration-level control}

The previous chapter discusses the velocity-level control of tasks. It is also 
possible to determine the double derivative of the joint-space variables corresponding to some
desired task acceleration. To see this, consider \autoref{eq:def_task_jacobian} and differentiate
with respect to time once more:
\begin{align}
    \ddot{\bm{\sigma}} = \frac{d}{dt}\left(\bm{J} \dot{\bm{q}}\right) = \dot{\bm{J}} \dot{\bm{q}} + \bm{J} \ddot{\bm{q}}
    \label{eq:task_acc_jacobian}
\end{align}
Writing the general solution to this equation solving for the joint accelerations
$\ddot{\bm{q}}$ gives
\begin{align}
    \ddot{\bm{q}} = \bm{J}^{+} \left(\ddot{\bm{\sigma}} - \dot{\bm{J}}\dot{\bm{q}}\right) +
    \left(\mathbb{I} - \bm{J}^{+}\bm{J}\right) \bm{z} \label{eq:task_acc_control}
\end{align}
for some arbitrary vector $\bm{z} \in \mathbb{R}^n$. Inspired from the
velocity-level control, one can define the desired joint accelerations as
\begin{align}
    \ddot{\bm{q}}_d = \bm{J}^{+} \left(\ddot{\bm{\sigma}}_d
    - \dot{\bm{J}}\dot{\bm{q}}\right) \label{eq:task_priority_acc}
\end{align}
One can impose the closed-loop characteristic of the task by defining the desired
task acceleration implicitly as
\begin{align}
    \left(\ddot{\bm{\sigma}}_d - \ddot{\bm{\sigma}}\right) +
    \bm{K}_d\left(\dot{\bm{\sigma}}_d - \dot{\bm{\sigma}}\right) +
    \bm{K}_p\left(\bm{\sigma}_d - \bm{\sigma}\right) = 0 \label{eq:task_acc}
\end{align}
where $\bm{K}_d$ and $\bm{K}_p$ are positive definite matrices. Substituting
\autoref{eq:task_acc} into the desired joint accelerations \autoref{eq:task_acc_jacobian},
and doing this for each task, one can get the desired joint accelerations for each task.
\begin{subequations}
\begin{align}
    \bm{J}_i\ddot{\bm{q}} &= -\dot{\bm{J}}_i\dot{\bm{q}} + \ddot{\bm{\sigma}}_{i,d} 
    + \bm{K}_{d,i}\left(\dot{\bm{\sigma}}_{i,d} - \dot{\bm{\sigma}}_i\right)
    + \bm{K}_{p,i}\left(\bm{\sigma}_{i,d} - \bm{\sigma}_i\right) \\
    &=: \bm{h}_i(\bm{q}, \dot{\bm{q}}, t) \\
    \ddot{\bm{q}}_d &= \bm{J}_1^{+} \bm{h}_1 + \left(\mathbb{I} - \bm{J}_1^+\bm{J}_1\right) \bm{J}_2^{+} \bm{h}_2
\end{align}
\end{subequations}
This method is called acceleration-level task priority control. The method can
be generalized to multiple tasks by using the same methods as presented in \autoref{sec:tpc_intro}.

\subsection{Low level joint-space control}

The aforementioned methods are, as previously mentioned, based on the assumption
that a controller exists that can generate the desired joint velocities $\dot{\bm{q}}_d(t)$.
In practice, this is not always the case, and there is certainly no guarentee that
$\dot{\bm{q}}_d(t) = \dot{\bm{q}}(t)$ at all times. This introduces the need for a
low-level joint-space controller that aims to track the desired joint velocities.
A simple PD controller is a simple way to achieve this;
\begin{align}
    \bm{\tau}_d(t) :=  \bm{\tau}_{\mathrm{PD}}(t) =
        \bm{K}_p \left( \bm{q}_d(t) - \bm{q}(t) \right)
        + \bm{K}_d \left( \dot{\bm{q}}_d(t) - \dot{\bm{q}}(t)\right)
\end{align}
Here, $\bm{K}_d$ and $\bm{K}_p$ are positive definite gain matrices to be tuned
and $\bm{\tau}_d(t)$ is the desired generalized torques acting on the robot. A
thruster allocation algorithm can be used to convert the generalized torques to
actuator commands \cite{fossen2021}. $\bm{q}_d(t)$, and in the case of
acceleration-level control, $\dot{\bm{q}}_d(t)$, can be calculated by
integrating the desired joint velocities or accelerations
\begin{subequations}
\begin{align}
    \bm{q}_d(t) = \int_0^t \dot{\bm{q}}_d(t) \, d\tau \\
    \dot{\bm{q}}_d(t) = \int_{0}^t \ddot{\bm{q}}_d(t)\, d\tau.
\end{align}
\end{subequations}
A simple way to improve this controller is to compensate for the gravity-, and
optionally the buoyancy-forces acting on the robot. This can be done by adding
a feedforward term to the controller:
\begin{align}
    \bm{\tau}_d(t) = \bm{\tau}_{\mathrm{PD+}}(t) :=
    \bm{\tau}_{\mathrm{PD}}(t) + \bm{g}(\bm{q}(t)),
\end{align}
where $\bm{g}(\bm{q}(t))$ is the gravity vector acting on the robot. Assuming the
model is on the very general form
\begin{align}
    \bm{M}(\bm{q}) \ddot{\bm{q}} + \bm{C}(\bm{q}, \dot{\bm{q}}) \dot{\bm{q}} + \bm{g}(\bm{q}) = \bm{\tau},
\end{align}
substituting $\bm{\tau}$ with $\bm{\tau}_d(t)$ gives
\begin{subequations}
\begin{align}
    \bm{M}(\bm{q}) \ddot{\bm{q}} + \bm{C}(\bm{q}, \dot{\bm{q}}) \dot{\bm{q}} + \bm{g}(\bm{q}) &= \bm{\tau}_{\mathrm{PD+}}(t) \\
    \bm{M}(\bm{q}) \ddot{\bm{q}} + \bm{C}(\bm{q}, \dot{\bm{q}}) \dot{\bm{q}} &= \bm{\tau}_{\mathrm{PD}}(t),
\end{align}
\end{subequations}
effectively compensating for the gravity forces acting on the robot. Integral
action can be added to the controller to improve tracking performance, but this
should be done with caution as integral action can introduce instability in the
system. This is espcially true in cases where some form of integral action is
present in the redundancy resolution algorithm \cite{fossen2021}.

It is also possible to use a feedback linearization technique to achieve the
desired joint velocities. By assuming that the robot's dynamic model is known,
one can set the desired joint acceleration by formulating the generalized
torques $\bm{\tau}$ as
\begin{align}
    \bm{\tau} = \bar{\bm{M}}(\bm{q}) \ddot{\bm{q}}_d + \bar{\bm{C}}(\bm{q}, \dot{\bm{q}}) \dot{\bm{q}} + \bar{\bm{g}}(\bm{q}) \label{eq:torque_feedback_lin}
\end{align}
where $\bar{\bm{M}}(\bm{q})$, $\bar{\bm{C}}(\bm{q}, \dot{\bm{q}})$ and
$\bar{\bm{g}}(\bm{q})$ are approximations of the robot's mass matrix, Coriolis
and centripetal forces (and damping), and gravity vector, respectively. Assuming
that the approximations are exact, and that the torque is feasible, one can easily
see that the joint acceleration is given by:
\begin{subequations}
\begin{align}
    \bm{M}(\bm{q}) \ddot{\bm{q}} + \bm{C}(\bm{q}, \dot{\bm{q}}) \dot{\bm{q}} + \bm{g}(\bm{q}) &= 
    \bar{\bm{M}}(\bm{q}) \ddot{\bm{q}}_d + \bar{\bm{C}}(\bm{q}, \dot{\bm{q}}) \dot{\bm{q}} + \bar{\bm{g}}(\bm{q}) \\
    \implies \bm{M}(\bm{q}) \ddot{\bm{q}} &= \bm{M}(\bm{q}) \ddot{\bm{q}}_d
\end{align}
\end{subequations}
Since the mass matrix is positive definite, there is an equivalence between the
desired joint acceleration and the actual joint acceleration. In practice
however, the approximations are not exact, and the torque might be innacurate or
not feasible due to actuator limits. Furthermore, the estimated joint velocities
and accelerations might be noisy, making the input torques innacurate.



% -----------------------------------------------------------------------------
\section{Dynamic-level Redundancy Resolution}

% -----------------------------------------------------------------------------
\section{Optimization Objective as Tasks}

Tasks can be generalized from the form presented in \autoref{eq:def_task}, where
the main objective of the task is to make a certain point attached to the robot
manipulator follow a certain trajectory. The task can be generalized to be the
orientation of the end-effector and/or some optimization objective. As presented
in\cite{nakamura1987}, the task can be defined as the gradient of an optimization
function. Consider an artificial potential function $P(\bm{q})$ and and a dissipative function
$D(\dot{\bm{q}})$. The task can then be defined as
\begin{align}
    \bm{\sigma} = -\nabla_{\bm{q}} P(\bm{q}) - \nabla_{\dot{\bm{q}}}D(\dot{\bm{q}})
\end{align}
In \cite{nakamura1987}, the authors show that, in simulation, a 4-jointed planar
manipulator can successfully avoid a rectangular obstacle using this method. This is
also shown in \cite{siciliano1991} where a 7-DOF planar manipulator has a path
following task with priority 1 and a circular obstacle avoidance task with priority 2.
Although this method does not use a dissipative function in the optimization objective.




% -----------------------------------------------------------------------------
\section{Singularity Robustness}

Considerations have to be taken into account when implementing the
pseudoinverse numerically on a computer. One of the most important considerations is the singularity
robustness of the algorithm. Although the pseudoinverse is defined for all matrices,
when the matrix is close to being singular, the pseudoinverse can be very sensitive
to small changes in the matrix. This might lead to very large input torques along
allmost-singular directions. This problem is discussed extensively in \cite{chiaverini1997}.
The following section will discuss the singularity robustness of the algorithm used in this
thesis as proposed by \cite{chiaverini1997}.

First, consider the problem of taking the pseudoinverse of an arbitrary matrix $\bm{J}$.
As discussed in \autoref{sec:pseudoinverse}, the SVD of a matrix $\bm{J}$ can be
written as
\begin{align}
    \bm{J} = \bm{U} \bm{\Sigma} \bm{V}^T
\end{align}
and the pseudoinverse of $J$ is
\begin{align}
    \bm{J}^+ = \bm{V} \bm{\Sigma}^+ \bm{U}^T
\end{align}
Rewriting the $\bm{U}$ and $\bm{V}$ matrices as
\begin{subequations}
\begin{align}
    \bm{U} &= \begin{bmatrix} \bm{u}_1 & \bm{u}_2 & \cdots & \bm{u}_n \end{bmatrix} \\
    \bm{V} &= \begin{bmatrix} \bm{v}_1 & \bm{v}_2 & \cdots & \bm{v}_m \end{bmatrix}
\end{align}
\end{subequations}
where $\bm{u}_i$ and $\bm{v}_i$ are the columns of $\bm{U}$ and $\bm{V}$ respectively.
$\bm{J}$ and its pseudoinverse can be written as
\begin{subequations}
\begin{align}
    \bm{J} &= \sum_{i=1}^r \sigma_i \bm{u}_i \bm{v}_i^T \\
    \bm{J}^+ &= \sum_{i=1}^r \frac{1}{\sigma_i} \bm{v}_i \bm{u}_i^T
\end{align}
\end{subequations}
From this, it is clear that when $\sigma_i$ is close to zero, the pseudoinverse
will be very sensitive to small changes in $\sigma_i$. One proposed solution to
this problem is the so-called \emph{damped pseudoinverse} which is defined as
\begin{align}
    \bm{J}^* := \sum_{i=1}^r \frac{\sigma_i}{\sigma_i^2 + \lambda^2} \bm{v}_i \bm{u}_i^T
\end{align}
We see that for large values of $\sigma_i$,
\begin{align}
    \frac{\sigma_i}{\sigma_i^2 + \lambda^2} \approx \frac{1}{\sigma_i}
\end{align}
and for small values of $\sigma_i$,
\begin{align}
    \frac{\sigma_i}{\sigma_i^2 + \lambda^2} \approx 0
\end{align}
This will make the pseudoinverse well-conditioned for all values of $\sigma_i$.
The trado-off is that the damped pseudoinverse will not be the true pseudoinverse.
This might lead to tasks with lower priority affecting the higher-priority tasks and
breaking some of the assumptions made when proving stability and task consistency.

A way to make the pseudoinverse more accurate when far from singularities is to
use the \emph{variable damped least-squares inverse} (VDLSI) proposed by \cite{chiaverini1997}.
This uses the fact that there is no need to damp the pseudoinverse when far from singularities.
The VDLSI is defined as
\begin{subequations}
\begin{align}
    \bm{J}^{\circ} := \sum_{i=1}^r \frac{\sigma_i}{\sigma_i^2 + \lambda_i^2(\sigma_i)} \bm{v}_i \bm{u}_i^T \\
    \lambda_i^2(\sigma_i) = \begin{cases}
        0 & ,\sigma_i \geq \varepsilon \\
        \left(1-\left(\frac{\sigma_i}{\varepsilon}\right)\right)\lambda_{max}^2 & ,\sigma_i < \varepsilon
    \end{cases}
\end{align}
\end{subequations}
where $\lambda_{max}^2$ and $\varepsilon$ are parameters that can be tuned. $\lambda_{max}$
determines the maximum damping factor and $\varepsilon$ determines a threshold for when
to start damping the pseudoinverse based on how close the singular values are to zero.
